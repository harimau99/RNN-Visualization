{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from misc import *\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 8\n",
    "data_dir = 'data'\n",
    "train_size = 94*3*7\n",
    "batch_size = 64\n",
    "n_lstm = 100\n",
    "epochs = 1000\n",
    "noise = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/space/text-dataset/lstm-visualization/misc.py:83: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  model = Model(input=input_layer, output=output_layer)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validation, X_test, Y_train, Y_validation, Y_test, le = load_prepare_data(data_dir, train_size, seed)\n",
    "model, lstm_activations = prepare_model(100, 'accuracy', X_train, Y_train, (0.0, 0.0), (0.0, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/space/text-dataset/lstm-visualization/misc.py:102: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  verbose=verbosity)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1974 samples, validate on 277 samples\n",
      "Epoch 1/100\n",
      "1974/1974 [==============================] - 2s - loss: 4.5528 - acc: 0.0081 - val_loss: 4.5458 - val_acc: 0.0072\n",
      "Epoch 2/100\n",
      "1974/1974 [==============================] - 2s - loss: 4.5446 - acc: 0.0101 - val_loss: 4.5446 - val_acc: 0.0072\n",
      "Epoch 3/100\n",
      "1974/1974 [==============================] - 2s - loss: 4.5321 - acc: 0.0177 - val_loss: 4.4976 - val_acc: 0.0289\n",
      "Epoch 4/100\n",
      "1974/1974 [==============================] - 2s - loss: 4.4323 - acc: 0.0172 - val_loss: 4.4545 - val_acc: 0.0289\n",
      "Epoch 5/100\n",
      "1974/1974 [==============================] - 2s - loss: 4.4078 - acc: 0.0167 - val_loss: 4.5390 - val_acc: 0.0217\n",
      "Epoch 6/100\n",
      "1974/1974 [==============================] - 2s - loss: 4.4490 - acc: 0.0208 - val_loss: 4.4317 - val_acc: 0.0144\n",
      "Epoch 7/100\n",
      "1974/1974 [==============================] - 2s - loss: 4.2946 - acc: 0.0218 - val_loss: 4.2269 - val_acc: 0.0253\n",
      "Epoch 8/100\n",
      "1974/1974 [==============================] - 2s - loss: 4.2429 - acc: 0.0147 - val_loss: 4.2174 - val_acc: 0.0072\n",
      "Epoch 9/100\n",
      "1974/1974 [==============================] - 2s - loss: 4.2064 - acc: 0.0152 - val_loss: 4.1399 - val_acc: 0.0289\n",
      "Epoch 10/100\n",
      "1974/1974 [==============================] - 2s - loss: 4.1184 - acc: 0.0162 - val_loss: 4.0192 - val_acc: 0.0108\n",
      "Epoch 11/100\n",
      "1974/1974 [==============================] - 2s - loss: 4.0209 - acc: 0.0193 - val_loss: 3.9773 - val_acc: 0.0181\n",
      "Epoch 12/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.9572 - acc: 0.0238 - val_loss: 3.9300 - val_acc: 0.0289\n",
      "Epoch 13/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.9571 - acc: 0.0223 - val_loss: 3.8996 - val_acc: 0.0325\n",
      "Epoch 14/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.9889 - acc: 0.0233 - val_loss: 3.9112 - val_acc: 0.0289\n",
      "Epoch 15/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.8151 - acc: 0.0309 - val_loss: 3.7860 - val_acc: 0.0325\n",
      "Epoch 16/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.8273 - acc: 0.0299 - val_loss: 3.7902 - val_acc: 0.0289\n",
      "Epoch 17/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.7473 - acc: 0.0274 - val_loss: 3.7254 - val_acc: 0.0578\n",
      "Epoch 18/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.6878 - acc: 0.0385 - val_loss: 3.7032 - val_acc: 0.0253\n",
      "Epoch 19/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.6045 - acc: 0.0496 - val_loss: 3.5844 - val_acc: 0.0542\n",
      "Epoch 20/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.5438 - acc: 0.0471 - val_loss: 3.5567 - val_acc: 0.0469\n",
      "Epoch 21/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.5234 - acc: 0.0507 - val_loss: 3.4424 - val_acc: 0.0686\n",
      "Epoch 22/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.4284 - acc: 0.0562 - val_loss: 3.3816 - val_acc: 0.0397\n",
      "Epoch 23/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.3459 - acc: 0.0578 - val_loss: 3.2998 - val_acc: 0.0505\n",
      "Epoch 24/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.2449 - acc: 0.0618 - val_loss: 3.2655 - val_acc: 0.0903\n",
      "Epoch 25/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.2384 - acc: 0.0714 - val_loss: 3.3187 - val_acc: 0.0578\n",
      "Epoch 26/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.7714 - acc: 0.0588 - val_loss: 3.6353 - val_acc: 0.0397\n",
      "Epoch 27/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.4980 - acc: 0.0522 - val_loss: 3.3066 - val_acc: 0.0866\n",
      "Epoch 28/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.2180 - acc: 0.0907 - val_loss: 3.2077 - val_acc: 0.0975\n",
      "Epoch 29/100\n",
      "1974/1974 [==============================] - 2s - loss: 3.0709 - acc: 0.1059 - val_loss: 3.0124 - val_acc: 0.1336\n",
      "Epoch 30/100\n",
      "1974/1974 [==============================] - 2s - loss: 2.9628 - acc: 0.1292 - val_loss: 2.9224 - val_acc: 0.1841\n",
      "Epoch 31/100\n",
      "1974/1974 [==============================] - 2s - loss: 2.8719 - acc: 0.1505 - val_loss: 2.8067 - val_acc: 0.1769\n",
      "Epoch 32/100\n",
      "1974/1974 [==============================] - 2s - loss: 2.7443 - acc: 0.1743 - val_loss: 2.7823 - val_acc: 0.1805\n",
      "Epoch 33/100\n",
      "1974/1974 [==============================] - 2s - loss: 2.6438 - acc: 0.2077 - val_loss: 2.6397 - val_acc: 0.2708\n",
      "Epoch 34/100\n",
      "1974/1974 [==============================] - 2s - loss: 2.5536 - acc: 0.2295 - val_loss: 2.6126 - val_acc: 0.2238\n",
      "Epoch 35/100\n",
      "1974/1974 [==============================] - 2s - loss: 2.5230 - acc: 0.2254 - val_loss: 2.5890 - val_acc: 0.2238\n",
      "Epoch 36/100\n",
      "1974/1974 [==============================] - 2s - loss: 2.4496 - acc: 0.2381 - val_loss: 2.4495 - val_acc: 0.2527\n",
      "Epoch 37/100\n",
      "1974/1974 [==============================] - 2s - loss: 2.3881 - acc: 0.2563 - val_loss: 2.3921 - val_acc: 0.2563\n",
      "Epoch 38/100\n",
      "1974/1974 [==============================] - 2s - loss: 2.2921 - acc: 0.2888 - val_loss: 2.2557 - val_acc: 0.3141\n",
      "Epoch 39/100\n",
      "1974/1974 [==============================] - 2s - loss: 2.2052 - acc: 0.3045 - val_loss: 2.2391 - val_acc: 0.2852\n",
      "Epoch 40/100\n",
      "1974/1974 [==============================] - 2s - loss: 2.2259 - acc: 0.2979 - val_loss: 2.2256 - val_acc: 0.3141\n",
      "Epoch 41/100\n",
      "1974/1974 [==============================] - 2s - loss: 2.1257 - acc: 0.3313 - val_loss: 2.0952 - val_acc: 0.3357\n",
      "Epoch 42/100\n",
      "1974/1974 [==============================] - 2s - loss: 2.0466 - acc: 0.3490 - val_loss: 2.1753 - val_acc: 0.3321\n",
      "Epoch 43/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.9728 - acc: 0.3718 - val_loss: 2.0002 - val_acc: 0.3538\n",
      "Epoch 44/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.8877 - acc: 0.4088 - val_loss: 1.9434 - val_acc: 0.3755\n",
      "Epoch 45/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.8248 - acc: 0.4144 - val_loss: 1.8613 - val_acc: 0.3935\n",
      "Epoch 46/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.7898 - acc: 0.4225 - val_loss: 1.8948 - val_acc: 0.3610\n",
      "Epoch 47/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.7426 - acc: 0.4488 - val_loss: 1.7781 - val_acc: 0.4404\n",
      "Epoch 48/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.7144 - acc: 0.4504 - val_loss: 1.8778 - val_acc: 0.4007\n",
      "Epoch 49/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.7331 - acc: 0.4311 - val_loss: 1.6837 - val_acc: 0.4404\n",
      "Epoch 50/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.5883 - acc: 0.4868 - val_loss: 1.6673 - val_acc: 0.4801\n",
      "Epoch 51/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.5137 - acc: 0.5238 - val_loss: 1.5667 - val_acc: 0.4801\n",
      "Epoch 52/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.5302 - acc: 0.4929 - val_loss: 1.6912 - val_acc: 0.4801\n",
      "Epoch 53/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.4941 - acc: 0.5268 - val_loss: 1.5724 - val_acc: 0.4657\n",
      "Epoch 54/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.4055 - acc: 0.5415 - val_loss: 1.5459 - val_acc: 0.4838\n",
      "Epoch 55/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.4113 - acc: 0.5410 - val_loss: 1.4955 - val_acc: 0.4982\n",
      "Epoch 56/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.3467 - acc: 0.5537 - val_loss: 1.3935 - val_acc: 0.5596\n",
      "Epoch 57/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.2994 - acc: 0.5836 - val_loss: 1.5487 - val_acc: 0.5271\n",
      "Epoch 58/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.3294 - acc: 0.5800 - val_loss: 1.4333 - val_acc: 0.5343\n",
      "Epoch 59/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.2991 - acc: 0.5704 - val_loss: 1.3371 - val_acc: 0.5921\n",
      "Epoch 60/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.2351 - acc: 0.5887 - val_loss: 1.3358 - val_acc: 0.5451\n",
      "Epoch 61/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.1708 - acc: 0.6185 - val_loss: 1.2938 - val_acc: 0.5993\n",
      "Epoch 62/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.0882 - acc: 0.6697 - val_loss: 1.1573 - val_acc: 0.6245\n",
      "Epoch 63/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.1126 - acc: 0.6596 - val_loss: 1.1970 - val_acc: 0.6426\n",
      "Epoch 64/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.0872 - acc: 0.6515 - val_loss: 1.2284 - val_acc: 0.5848\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1974/1974 [==============================] - 2s - loss: 1.0627 - acc: 0.6662 - val_loss: 1.1609 - val_acc: 0.6101\n",
      "Epoch 66/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.9936 - acc: 0.6793 - val_loss: 1.1411 - val_acc: 0.6354\n",
      "Epoch 67/100\n",
      "1974/1974 [==============================] - 2s - loss: 1.0325 - acc: 0.6707 - val_loss: 1.2369 - val_acc: 0.5921\n",
      "Epoch 68/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.9647 - acc: 0.7011 - val_loss: 1.0735 - val_acc: 0.6462\n",
      "Epoch 69/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.9660 - acc: 0.6879 - val_loss: 1.0804 - val_acc: 0.6462\n",
      "Epoch 70/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.9037 - acc: 0.7112 - val_loss: 1.0106 - val_acc: 0.6606\n",
      "Epoch 71/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.8354 - acc: 0.7234 - val_loss: 1.0039 - val_acc: 0.7004\n",
      "Epoch 72/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.8372 - acc: 0.7310 - val_loss: 0.9235 - val_acc: 0.6968\n",
      "Epoch 73/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.7580 - acc: 0.7730 - val_loss: 0.8669 - val_acc: 0.7220\n",
      "Epoch 74/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.7661 - acc: 0.7589 - val_loss: 0.8169 - val_acc: 0.7437\n",
      "Epoch 75/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.7582 - acc: 0.7482 - val_loss: 0.8445 - val_acc: 0.7437\n",
      "Epoch 76/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.7963 - acc: 0.7345 - val_loss: 1.0181 - val_acc: 0.6679\n",
      "Epoch 77/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.7452 - acc: 0.7604 - val_loss: 0.8957 - val_acc: 0.7184\n",
      "Epoch 78/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.7563 - acc: 0.7467 - val_loss: 0.8301 - val_acc: 0.7256\n",
      "Epoch 79/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.7139 - acc: 0.7675 - val_loss: 0.7351 - val_acc: 0.8123\n",
      "Epoch 80/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.6116 - acc: 0.8171 - val_loss: 0.7055 - val_acc: 0.7762\n",
      "Epoch 81/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.5392 - acc: 0.8399 - val_loss: 0.6347 - val_acc: 0.7942\n",
      "Epoch 82/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.6403 - acc: 0.7893 - val_loss: 0.7002 - val_acc: 0.7798\n",
      "Epoch 83/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.5755 - acc: 0.8227 - val_loss: 0.6600 - val_acc: 0.7834\n",
      "Epoch 84/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.5445 - acc: 0.8359 - val_loss: 0.6924 - val_acc: 0.7942\n",
      "Epoch 85/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.5003 - acc: 0.8501 - val_loss: 0.5633 - val_acc: 0.8484\n",
      "Epoch 86/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.4385 - acc: 0.8784 - val_loss: 0.5594 - val_acc: 0.8412\n",
      "Epoch 87/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.4148 - acc: 0.8799 - val_loss: 0.5663 - val_acc: 0.8159\n",
      "Epoch 88/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.4002 - acc: 0.8764 - val_loss: 0.5480 - val_acc: 0.8339\n",
      "Epoch 89/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.3881 - acc: 0.8804 - val_loss: 0.4716 - val_acc: 0.8592\n",
      "Epoch 90/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.4488 - acc: 0.8495 - val_loss: 0.6165 - val_acc: 0.7978\n",
      "Epoch 91/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.4231 - acc: 0.8663 - val_loss: 0.5390 - val_acc: 0.8375\n",
      "Epoch 92/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.3844 - acc: 0.8769 - val_loss: 0.4385 - val_acc: 0.8736\n",
      "Epoch 93/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.3582 - acc: 0.8926 - val_loss: 0.4351 - val_acc: 0.8700\n",
      "Epoch 94/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.3204 - acc: 0.9032 - val_loss: 0.3979 - val_acc: 0.8845\n",
      "Epoch 95/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.3190 - acc: 0.9043 - val_loss: 0.4801 - val_acc: 0.8520\n",
      "Epoch 96/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.2735 - acc: 0.9174 - val_loss: 0.4016 - val_acc: 0.8809\n",
      "Epoch 97/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.3079 - acc: 0.9037 - val_loss: 0.4244 - val_acc: 0.8881\n",
      "Epoch 98/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.3124 - acc: 0.9032 - val_loss: 0.4585 - val_acc: 0.8628\n",
      "Epoch 99/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.3152 - acc: 0.9012 - val_loss: 0.4587 - val_acc: 0.8809\n",
      "Epoch 100/100\n",
      "1974/1974 [==============================] - 2s - loss: 0.3137 - acc: 0.9007 - val_loss: 0.3146 - val_acc: 0.8953\n"
     ]
    }
   ],
   "source": [
    "model, history = fit_model(model, X_train, Y_train, X_validation, Y_validation, seed, epochs=100, patience=15, batch_size=64, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86856 samples, validate on 21714 samples\n",
      "Epoch 1/5\n",
      "86856/86856 [==============================] - 1s - loss: 0.0384 - val_loss: 0.0259\n",
      "Epoch 2/5\n",
      " 5376/86856 [>.............................] - ETA: 1s - loss: 0.0257"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "def custom_activation(x):\n",
    "    return x\n",
    "\n",
    "act = lstm_activations.predict(X_train)\n",
    "labels = le.inverse_transform(np.argmax(Y_train, axis=1))\n",
    "X_autoencoder, Y_autoencoder = prepare_autoencoder_input(act, noise, seed, min_=10, max_=65)\n",
    "\n",
    "decoded3D, encoded3D = prepare_autoencoder(n_lstm, 3, dense_1=600, dense_2=150, activation=custom_activation)\n",
    "decoded3D, _ = fit_autoencoder(decoded3D, X_autoencoder, Y_autoencoder, seed, patience=5, verbosity=1,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = lstm_activations.predict(X_train)\n",
    "labels = le.inverse_transform(np.argmax(Y_train, axis=1))\n",
    "set_labels = sorted(set(labels))\n",
    "plot_3D(set_labels, encoded3D, act, labels, 'LSTM logits 3D', x_l=-2.5,\n",
    "            x_h=2.5, y_l=-2.5, y_h=2.5, figsize=(13, 13), pointsize=5, max_steps=90, log=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
